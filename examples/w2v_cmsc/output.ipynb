{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I save the path of each of my experiments, so I can quickly recover them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrain models:\n",
    "\n",
    "- [wcr-all-120] /volume/deepecg/fairseq-signals/outputs/2024-09-05/13-40-53/checkpoints-all/\n",
    "- [wcr-50k-200] /volume/deepecg/fairseq-signals/outputs/2024-08-22/14-31-06/checkpoints-50k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finetune models\n",
    "\n",
    "- [wcr-all-120 + acs ft] /volume/deepecg/fairseq-signals/outputs/2024-09-09/02-41-20/checkpoints-acs/\n",
    "- [wcr-all-120 + fevg ft] /volume/deepecg/fairseq-signals/outputs/2024-09-08/18-37-44/checkpoints/\n",
    "- [wcr-all-120 + bp ft] /volume/deepecg/fairseq-signals/outputs/2024-09-09/03-52-10/checkpoints-bp/\n",
    "- [wcr-all-120 + afib ft] /volume/deepecg/fairseq-signals/outputs/2024-09-09/02-29-11/checkpoints-afib\n",
    "- [wcr-50k-200 + fevg ft] /volume/deepecg/fairseq-signals/outputs/2024-09-06/04-22-33/checkpoints/\n",
    "- [wcr-50k-200 + acs ft] /volume/deepecg/fairseq-signals/outputs/2024-09-05/17-43-03/checkpoints/\n",
    "\n",
    "### Asymmetric loss\n",
    "- [wrc-all-120 + acs ft] /volume/deepecg/fairseq-signals/outputs/2024-09-11/17-18-19/checkpoints-acs-as/\n",
    "- [wcr-all-120 + afib ft] /volume/deepecg/fairseq-signals/outputs/2024-09-11/17-18-24/checkpoints-afib-as/\n",
    "- [wcr-all-120 + fevg ft] /volume/deepecg/fairseq-signals/outputs/2024-09-12/00-50-42/checkpoints-fevg-as/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Linear evaluation models\n",
    "\n",
    "- [wcr-all-120 + acs le] /volume/deepecg/fairseq-signals/outputs/2024-09-10/12-52-38/checkpoints-acs/\n",
    "- [wcr-all-120 + afib le] /volume/deepecg/fairseq-signals/outputs/2024-09-10/12-53-39/checkpoints-afib/\n",
    "- [wcr-all-120 + fevg le] /volume/deepecg/fairseq-signals/outputs/2024-09-11/18-32-18/checkpoints-fevg/\n",
    "- [wcr-all-120 + lqts le] /volume/deepecg/fairseq-signals/outputs/2024-09-16/04-15-17/checkpoints-le-lqts\n",
    "- [wcr-all-120 + lqts le, bs=32] /volume/deepecg/fairseq-signals/outputs/2024-09-16/04-46-42/checkpoints-le-lqts\n",
    "- [wcr-all-120 + lqts ft] /volume/deepecg/fairseq-signals/outputs/2024-09-16/04-20-06/checkpoints-lqts/\n",
    "- [wcr-all-120 + lqts type le] /volume/deepecg/fairseq-signals/outputs/2024-09-16/04-18-12/checkpoints-le-lqts-type\n",
    "- [wcr-all-120 + lqts type ft] /volume/deepecg/fairseq-signals/outputs/2024-09-16/04-22-04/checkpoints-lqts-type \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/00-52-58/checkpoint_last-ft-fevg-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/02-30-25/checkpoint_last-ft-fevg-v2-50-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/02-31-55/checkpoint_last-ft-fevg-v2-40-bce\n",
    "\n",
    "\n",
    "#### lqts - last\n",
    "\n",
    "#### lqts-type - e2e\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/16-18-24/checkpoint_e2e-e2e-lqts-type-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-10/04-39-24/checkpoint_e2e-e2e-lqts-type-as\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-10/04-29-09/checkpoint_e2e-e2e-lqts-type-bf\n",
    "#### lqts-type - last\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/22-39-20/checkpoint_last-le-lqts-type-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/16-35-31/checkpoint_last-ft-lqts-type-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-10/04-44-18/checkpoint_last-le-lqts-type-as\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-10/04-57-09/checkpoint_last-ft-lqts-type-as\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-10/04-14-58/checkpoint_last-le-lqts-type-bf\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-10/04-10-13/checkpoint_last-ft-lqts-type-bf\n",
    "#### lqts-type - 200\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/23-45-49/checkpoint200-le-lqts-type-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/23-59-42/checkpoint200-ft-lqts-type-bce\n",
    "#### lqts-type - 150\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/23-45-08/checkpoint150-le-lqts-type-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-09/00-00-14/checkpoint150-ft-lqts-type-bce\n",
    "#### lqts-type - 100\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/23-42-01/checkpoint100-le-lqts-type-bce\n",
    "- /volume/deepecg/fairseq-signals/outputs/2024-10-08/23-59-26/checkpoint100-ft-lqts-type-bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES=0 fairseq-hydra-train common.fp16=true task.data=/media/data1/achilsowa/datasets/fairseq/mhi-mimic-code15/manifest/finetune/labels-77 model.model_path=/media/data1/achilsowa/results/fairseq/outputs/2024-09-22/03-16-32/checkpoints-all/checkpoint_last.pt model._name=ecg_transformer_attn_classifier +task.npy_dataset=true model.num_labels=77 criterion._name=binary_cross_entropy_with_logits checkpoint.save_dir=checkpoint_last-ft-labels-77-bce-attn --config-dir examples/w2v_cmsc/config/finetuning/ecg_transformer --config-name diagnosis\n",
      "CUDA_VISIBLE_DEVICES=1 fairseq-hydra-inference task.data=/media/data1/achilsowa/datasets/fairseq/mhi-mimic-code15/manifest/finetune/fevg-reg common_eval.path=/volume/deepecg/fairseq-signals/outputs/2024-10-17/05-09-15/checkpoint_last-ft-fevg-reg-mse/checkpoint_best.pt common_eval.results_path=/volume/deepecg/fairseq-signals/outputs/2024-10-17/05-09-15/checkpoint_last-ft-fevg-reg-mse task.npy_dataset=true model.num_labels=1 dataset.valid_subset=mimic_cleaned --config-dir examples/w2v_cmsc/config/finetuning/ecg_transformer --config-name eval\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def generate_train_cli(\n",
    "    devices=1,\n",
    "    encoder='_last',\n",
    "    task = '77-labels',\n",
    "    num_labels = 77,\n",
    "    mode='ft', # possible values are 'ft', 'le', 'e2e'\n",
    "    is_df=True,\n",
    "    cls='',\n",
    "    wd=0,\n",
    "    criterion='binary_cross_entropy_with_logits'\n",
    "):    \n",
    "    def loss_str():\n",
    "        if criterion == 'asymmetric':\n",
    "            return 'as'\n",
    "        if criterion == 'binary_focal':\n",
    "            return 'bf'\n",
    "        if criterion == 'mse':\n",
    "            return 'mse'\n",
    "        if criterion == 'binary_cross_entropy_with_logits':\n",
    "            return 'bce'\n",
    "        if criterion == 'mlsml':\n",
    "            return 'mlsml'\n",
    "        assert False, 'Invalid error'\n",
    "    \n",
    "    cli = f'CUDA_VISIBLE_DEVICES={devices} fairseq-hydra-train '\n",
    "    if criterion == 'mse':\n",
    "        cli += f'common.fp16=false '\n",
    "    else:\n",
    "        cli +=f'common.fp16=true '\n",
    "    cli += f'task.data=/media/data1/achilsowa/datasets/fairseq/mhi-mimic-code15/manifest/finetune/{task} '\n",
    "    if mode == 'e2e':\n",
    "        cli += f'model.no_pretrained_weights=true '\n",
    "        encoder = '_e2e'\n",
    "    else:\n",
    "        cli += f'model.model_path=/media/data1/achilsowa/results/fairseq/outputs/2024-09-22/03-16-32/checkpoints-all/checkpoint{encoder}.pt '\n",
    "    if cls == 'attn':\n",
    "        cli += f'model._name=ecg_transformer_attn_classifier '\n",
    "    if wd:\n",
    "        cli += f'optimizer.weight_decay={wd} '\n",
    "    if mode == 'le':\n",
    "        cli += f'model.linear_evaluation=true '\n",
    "    \n",
    "    if is_df:\n",
    "        cli += f'+task.df_dataset=true '\n",
    "    else:\n",
    "        cli += f'+task.npy_dataset=true '\n",
    "\n",
    "    cli += f'model.num_labels={num_labels} '\n",
    "    cli += f'criterion._name={criterion} '\n",
    "    if cls == 'attn':\n",
    "        cls = '-attn'\n",
    "    cli += f'checkpoint.save_dir=checkpoint{encoder}-{mode}-{task}-{loss_str()}{cls} '\n",
    "    cli += '--config-dir examples/w2v_cmsc/config/finetuning/ecg_transformer --config-name diagnosis'\n",
    "\n",
    "    return cli\n",
    "\n",
    "def generate_test_cli(\n",
    "    devices=1,\n",
    "    encoder='_best',\n",
    "    task='labels-77',\n",
    "    subset=None,\n",
    "    eval_path='',\n",
    "    eval_key=None,\n",
    "    is_df=True,\n",
    "    num_labels=77,\n",
    "    root_dir = '/volume/deepecg/fairseq-signals/outputs/'\n",
    "):   \n",
    "    if eval_key is not None:\n",
    "        eval_path = get_path(eval_key, root_dir=root_dir)\n",
    "    task_path = os.path.join(eval_path, f'checkpoint{encoder}.pt')\n",
    "    cli = f'CUDA_VISIBLE_DEVICES={devices} fairseq-hydra-inference '\n",
    "    cli += f'task.data=/media/data1/achilsowa/datasets/fairseq/mhi-mimic-code15/manifest/finetune/{task} '\n",
    "    cli += f'common_eval.path={task_path} '\n",
    "    cli += f'common_eval.results_path={eval_path} '\n",
    "    if is_df:\n",
    "        cli += f'task.df_dataset=true '\n",
    "    else:\n",
    "        cli += f'task.npy_dataset=true '\n",
    "    cli += f'model.num_labels={num_labels} '\n",
    "    if subset is not None:\n",
    "        cli += f'dataset.valid_subset={subset} '\n",
    "    cli += '--config-dir examples/w2v_cmsc/config/finetuning/ecg_transformer --config-name eval'\n",
    "    return cli\n",
    "\n",
    "def get_path(key, root_dir = '/volume/deepecg/fairseq-signals/outputs/'):\n",
    "    matching_dirs = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        # Get the depth of the current directory relative to the root\n",
    "        depth = len(os.path.relpath(dirpath, root_dir).split(os.sep))\n",
    "        # Only proceed if the depth is less than or equal to 2 (the first two levels)\n",
    "        if depth <= 2:\n",
    "            #print(dirnames)\n",
    "            for dirname in dirnames:\n",
    "                if dirname.endswith(key):\n",
    "                    matching_dirs.append(os.path.join(dirpath, dirname))\n",
    "        else: \n",
    "            # Stop walking deeper if we've reached beyond the second level\n",
    "            del dirnames[:]  # Prevents os.walk from going deeper\n",
    "    assert len(matching_dirs) == 1, f'Expected one directory but found {matching_dirs}'\n",
    "    return matching_dirs[0]\n",
    "\n",
    "\n",
    "def check_dataset(ds_path, verbose=False):\n",
    "    ds_path = os.path.join('/media/data1/achilsowa/datasets/fairseq/mhi-mimic-code15/manifest/finetune', ds_path)\n",
    "    with open(ds_path, \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            items = line.strip().split(\":\")\n",
    "            assert len(items) == 2, line\n",
    "            key, value = items\n",
    "            if verbose: \n",
    "                print(key, '=', value)\n",
    "            if key == \"x_path\":\n",
    "                assert os.path.exists(value), f'file {value} not found'\n",
    "            elif key == \"y_path\":\n",
    "                assert os.path.exists(value), f'file {value} not found'\n",
    "\n",
    "\n",
    "traincli = generate_train_cli(\n",
    "    devices=0,\n",
    "    encoder='_last',\n",
    "    task='labels-77',\n",
    "    is_df=False,\n",
    "    num_labels=77,\n",
    "    mode='ft',\n",
    "    cls='attn',\n",
    "    criterion='binary_cross_entropy_with_logits'\n",
    "    #criterion='binary_focal'\n",
    "    #criterion='asymmetric',\n",
    "    #criterion='mse',\n",
    "    #criterion='mlsml'\n",
    ")\n",
    "\n",
    "test_key='last-ft-afib-v3-bce-attn'\n",
    "test_key='last-ft-fevg-reg-mse'\n",
    "testcli = generate_test_cli(\n",
    "    devices=1,\n",
    "    eval_key=test_key,\n",
    "\n",
    "    \n",
    "    encoder='_best',\n",
    "    task='fevg-reg',\n",
    "    is_df=False,\n",
    "    subset='mimic_cleaned',\n",
    "    num_labels=1,\n",
    "    #root_dir = '/media/data1/achilsowa/results/fairseq/outputs/'\n",
    ")\n",
    "\n",
    "print(traincli)\n",
    "print(testcli)\n",
    "#check_dataset('labels-77/ukbb_raw.tsv')\n",
    "\n",
    "#get_path(test_key)\n",
    "\n",
    "print('---------')\n",
    "for k in ['e2e-e2e-labels-77-bce', 'last-le-labels-77-bce', 'last-ft-labels-77-bce', 'last-ft-labels-77-bf']:\n",
    "    continue\n",
    "    for s in ['mhi_adjusted', 'ptb_cleaned', 'mimic_cleaned', 'ukbb_cleaned_high_pass_scaled']:\n",
    "        check_dataset(f'labels-77/{s}.tsv')\n",
    "        print(generate_test_cli(\n",
    "            devices=3, eval_key=k, encoder='_best', task='labels-77', subset=s, num_labels=77\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-1502c6b8b9ea>:4: DtypeWarning: Columns (44,45,66,73,74,95,97,105,106,108,124,128,134,141,142,143,167,172,176,177,179,181,183,189,194,196,197,202,208,217,218,222,223,252,412,441,442,448,495,497,503,661) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'/media/data1/ravram/DeepECG_Datasets/{suffix}_filtered_LVEF_Continuous.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "suffix = 'test'\n",
    "df = pd.read_csv(f'/media/data1/ravram/DeepECG_Datasets/{suffix}_filtered_LVEF_Continuous.csv')\n",
    "df_lite = df[['new_PatientID', 'npy_path', 'Visually Estimated EF_tte_lvef',]]\n",
    "df_lite.to_csv(f'/media/data1/ravram/DeepECG_Datasets/{suffix}_filtered_lite_LVEF_Continuous.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=1 fairseq-hydra-train common.fp16=true task.data=/media/data1/achilsowa/datasets/fairseq/mhi-mimic-code15/manifest/finetune/afib-v2 model.model_path=/media/data1/achilsowa/results/fairseq/outputs/2024-09-22/03-16-32/checkpoints-all/checkpoint_last.pt +task.df_dataset=true model.num_labels=2 criterion._name=binary_cross_entropy_with_logits checkpoint.save_dir=checkpoint_last-ft-afib-v2-bce --config-dir examples/w2v_cmsc/config/finetuning/ecg_transformer --config-name diagnosis &\n",
    "CUDA_VISIBLE_DEVICES=2 fairseq-hydra-train common.fp16=true task.data=/media/data1/achilsowa/datasets/fairseq/mhi-mimic-code15/manifest/finetune/afib-v2-5 model.model_path=/media/data1/achilsowa/results/fairseq/outputs/2024-09-22/03-16-32/checkpoints-all/checkpoint_last.pt +task.df_dataset=true model.num_labels=1 criterion._name=binary_cross_entropy_with_logits checkpoint.save_dir=checkpoint_last-ft-afib-v2-5-bce --config-dir examples/w2v_cmsc/config/finetuning/ecg_transformer --config-name diagnosis &\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
