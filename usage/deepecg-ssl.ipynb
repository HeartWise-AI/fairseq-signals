{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook describe how to load DeepECG-SSL and use it on your personal training pipeline\n",
    "\n",
    "- Make sure you deployed [`Fairseq-signals`](https://github.com/HeartWise-AI/fairseq-signals) locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import useful old code\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Dict, Optional, Union\n",
    "\n",
    "#TODO: configure it\n",
    "project_dir = ##INIT_TO_FAIRSEQ_SIGNAL_PATH\n",
    "root_dir = project_dir\n",
    "if not root_dir in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"checkpoint_utils\", f\"{project_dir}/fairseq_signals/utils/checkpoint_utils.py\")\n",
    "checkpoint_utils = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(checkpoint_utils)\n",
    "\n",
    "\n",
    "class WCREcgTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_path: str,\n",
    "        pretrained_path: str = None,\n",
    "        overrides: Optional[Dict[str, Any]] = None,\n",
    "        task=None,\n",
    "        strict=True,\n",
    "        suffix=\"\",\n",
    "        num_shards=1,\n",
    "        state=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        overrides = {} if overrides is None else vars(overrides)\n",
    "        if pretrained_path is not None:\n",
    "            overrides.update({\"model_path\": pretrained_path})\n",
    "        model, saved_cfg, task = checkpoint_utils.load_model_and_task(\n",
    "            model_path,\n",
    "            arg_overrides=overrides,\n",
    "            suffix=suffix\n",
    "        )\n",
    "\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x, padding_mask=None):\n",
    "        net_input = { \"source\": x, \"padding_mask\": padding_mask}\n",
    "        net_output = self.model(**net_input)\n",
    "        return self.model.get_logits(net_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "m_root = '/media/data1/achilsowa/results/fairseq/outputs/'\n",
    "\n",
    "m_paths = {\n",
    "    \"SSL\": '', #SSL_PATH\n",
    "    \"FT_AFIB-5\": '', #SSL_PATH\n",
    "    \"FT_LABELS-77\": os.path.join(m_root, \"2024-10-08/04-39-01/checkpoint_last-ft-labels-77-bce/checkpoint_best.pt\")\n",
    "}\n",
    "\n",
    "# Get the path to the root directory of your project\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # Adjust according to your folder depth\n",
    "\n",
    "# Add the root directory to sys.path\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "from models.modules.wcr import WCREcgTransformer\n",
    "\n",
    "\n",
    "model_ssl = WCREcgTransformer(m_paths['FT_AFIB'], m_paths['SSL'])\n",
    "model_fevg = WCREcgTransformer(m_paths['FT_FEVG-REG'], m_paths['SSL'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
